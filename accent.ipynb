''' 
Completed on Friday, 9th July 2021. Code tested and debugged. Accuracy of the model is 90%. Tensorflow is used for creating the Ml model. Working of the Model is explained with the help of comments to some extent. This 
is an example of a convolutional neural net with fashion mnist. NOTE: This model is created using tensorflow 2.0 and viewers don't need to worry about every tiny details of the code instead are recommended 
to take a look on the broader picture. 
'''
#importing important libraries

import tensorflow as tf
import numpy as np 
import tensorflow_datasets as tfds 

#loading fashion_mnist dataset from tensorflow_datasets
dataset, metadata= tfds.load(name='fashion_mnist',as_supervised=True, with_info=True)# if True as_supervised argument returns the image and label as a tuple and with_info returns the meatdata of the dataset. the .load() method builds, downloads and prepares the dataset passed with the name argument.
train_dataset, test_dataset= dataset['train'], dataset['test']#mistakenly assigned the test_dataset variable with the train split. (Debugging Status: Fixed). 

# normalizes the data by converting 0-225 value to a float ranging between 0 and 1 to ease matrix multiplication and keep it simple and illustratable.
def normalize(images,labels):# takes images and labels as inputs
    images= tf.cast(images,tf.float32)#.cast() method changes the data type of the tensors to floating point interger.
    images /=225 # converts value of tensors ranging from 0-225 to a float between 0 and 1.
    return images,labels # returns normalised values of only the images. Labels are untouched. 


train_dataset = train_dataset.map(normalize)# normalises every elemement of the train_dataset with the help of .map() method. NOTE: the normalised function is not executed instead it's address is left to the map function.
test_dataset  = test_dataset.map(normalize)# normalises every elemement of the test_dataset with the help of .map() method. NOTE: the normalised function is not executed instead it's address is left to the map function.
train_dataset = train_dataset.cache()# train_dataset is cached(stored in the RAM) for faster execution.
test_dataset  = test_dataset.cache()# test_dataset is cached(stored in the RAM) for faster execution.

# creates the layers of the models. Layers : 2D convolutions, Maxpooling, Flatten,Dense(hidden layer),Dense(output layer), Activations: ReLU and softmax.
model = tf.keras.Sequential([ 
    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,
                           input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D((2, 2), strides=2),
    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),
    tf.keras.layers.MaxPooling2D((2, 2), strides=2),
    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation=tf.nn.relu),
    tf.keras.layers.MaxPooling2D((2, 2), strides=2),
    
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Flatten(), 
    tf.keras.layers.Dense(512, activation=tf.nn.relu),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])

#compiles the model. Optimiser: Adam, Loss metric: Sparse Categorical Crossentrophy, Evaluation metric: accuracy
model.compile(optimizer=tf.keras.optimizers.Adam(0.001),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])

train_dataset= train_dataset.cache().repeat().shuffle(60000).batch(32)# train_dataset caches train_dataset applying shuffle and repeat to avoid chances of overfitting
test_dataset=  test_dataset.cache().batch(32)## train_dataset caches train_dataset applying shuffle and repeat to avoid chances of overfitting.(Debugging Status: Fixed)
model.fit(train_dataset,validation_data=test_dataset,epochs=5,steps_per_epoch=1875)# fits the training data with 5 epochs.
a,b=model.evaluate(test_dataset)


'''


Implementation of the model is done with a low level library (Tensorflow). For faster and easier model creation Keras API is recommended for students in high school that provides high level understanding of DL model.
Viewers who are not familiar with Deep Learning, keras Tensorflow2.0 API and numpy are provided with the supplemetary links .

Supplements:
3Blue1Brown's exceptional playlist on Deep neural networks and it's working. https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi 
Keith Galli's video on Introduction to Neural Networks in Python with Tensorflow with Keras API. https://www.youtube.com/watch?v=aBIGJeHRZLQ
Keith Galli's video on Complete Python NumPy Tutorial (Creating Arrays, Indexing, Math, Statistics, Reshaping) .https://www.youtube.com/watch?v=GB9ByFAIAH4

These videos would provide a descent understanding of neural nets, keras and numpy to get started creating simple neural nets.
'''